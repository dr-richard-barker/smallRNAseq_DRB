Note: This small RNA sequencing plan has been adapted from the NFCore smrnaseq pipeline ( https://hub.docker.com/r/nfcore/smrnaseq/ )

Quick Start

Install nextflow (>=20.04.0)
Install any of Docker, Singularity, Podman, Shifter or Charliecloud for full pipeline reproducibility (please only use Conda as a last resort; see docs)
Download the pipeline and test it on a minimal dataset with a single command:
nextflow run nf-core/smrnaseq -profile test,<docker/singularity/podman/shifter/charliecloud/conda/institute>
Please check nf-core/configs to see if a custom config file to run nf-core pipelines already exists for your Institute. 
If so, you can simply use -profile <institute> in your command. 
This will enable either docker or singularity and set the appropriate execution settings for your local compute environment.
Start running your own analysis!
nextflow run nf-core/smrnaseq -profile <docker/singularity/podman/shifter/charliecloud/conda/institute> --input '*_R{1,2}.fastq.gz' --genome GRCh37
See usage docs for all of the available options when running the pipeline.

Pipeline summary
Raw read QC (FastQC)
Adapter trimming (Trim Galore!)
Insert Size calculation
Collapse reads (seqcluster)
Alignment against miRBase mature miRNA (Bowtie1)
Alignment against miRBase hairpin
Unaligned reads from step 3 (Bowtie1)
Collapsed reads from step 2.2 (Bowtie1)
Post-alignment processing of miRBase hairpin
Basic statistics from step 3 and step 4.1 (SAMtools)
Analysis on miRBase hairpin counts (edgeR)
TMM normalization and a table of top expression hairpin
MDS plot clustering samples
Heatmap of sample similarities
miRNA and isomiR annotation from step 4.1 (mirtop)
Alignment against host reference genome (Bowtie1)
Post-alignment processing of alignment against host reference genome (SAMtools)
Novel miRNAs and known miRNAs discovery (MiRDeep2)
Mapping against reference genome with the mapper module
Known and novel miRNA discovery with the mirdeep2 module
miRNA quality control (mirtrace)
Present QC for raw read, alignment, and expression results (MultiQC)

Introduction
nf-core/smrnaseq is a bioinformatics best-practice analysis pipeline used for small RNA sequencing data analysis.
This document describes the output produced by the pipeline. Most of the plots are taken from the MultiQC report, which summarises results at the end of the pipeline.
The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.
Pipeline overview
The pipeline is built using Nextflow and processes data using the following steps:
FastQC - read quality control
FastP - adapter trimming
Bowtie2 - contamination filtering
Bowtie - alignment against mature miRNAs and miRNA precursors (hairpins)
SAMtools - alignment result processing and feature counting
edgeR - normalization, MDS plot and sample pairwise distance heatmap
Bowtie - alignment against reference genome for QC purpose
mirtop - miRNA and isomiR annotation
miRDeep2 - known and novel miRNA annotation
miRTrace - a comprehensive tool for QC purpose
MultiQC - aggregate report, describing results of the whole pipeline
Pipeline information - Report metrics generated during the workflow execution
FastQC
Output files




FastQC gives general quality metrics about your sequenced reads. It provides information about the quality score distribution across your reads, per base sequence content (%A/T/G/C), adapter contamination and overrepresented sequences. For further reading and documentation see the FastQC help pages.

FastP
FastP is used for removal of adapter contamination and trimming of low quality regions.
MultiQC reports the percentage of bases removed by FastP in the General Statistics table, along some further information on the results.
Output directory: results/fastp
Contains FastQ files with quality and adapter trimmed reads for each sample, along with a log file describing the trimming.
sample_fastp.json - JSON report file with information on parameters and trimming metrics
sample_fastp.html - HTML report with some visualizations of trimming metrics
FastP can automatically detect adapter sequences when not specified directly by the user - the pipeline also comes with a feature and a supplied miRNA adapters file to ensure adapters auto-detected are more accurate. If there are needs to add more known miRNA adapters to this list, please open a pull request.

Bowtie2
Bowtie2 is used to align the reads to user-defined databases of contaminants.
MultiQC reports the number of reads that were removed by each of the contaminant databases.

Bowtie
Bowtie is used for mapping adapter trimmed reads against the mature miRNAs and miRNA precursors (hairpins) of the chosen database miRBase or MirGeneDB.
Output directory: results/samtools
sample_mature.bam: The aligned BAM file of alignment against mature miRNAs
sample_mature_unmapped.fq.gz: Unmapped reads against mature miRNAs This file will be used as input for the alignment against miRNA precursors (hairpins)
sample_mature_hairpin.bam: The aligned BAM file of alignment against miRNA precursors (hairpins) that didn't map to the mature
sample_mature_hairpin_unmapped.fq.gz: Unmapped reads against miRNA precursors (hairpins)
sample_mature_hairpin_genome.bam: The aligned BAM file of alignment against that didn't map to the precursor.

SAMtools
SAMtools is used for sorting and indexing the output BAM files from Bowtie. In addition, the numbers of features are counted with the idxstats option.
Output directory: results/samtools/samtools_stats
stats|idxstats|flagstat: BAM stats for each of the files listed above.

edgeR
edgeR is an R package used for differential expression analysis of RNA-seq expression profiles.
Output directory: results/edgeR
[mature/hairpin]_normalized_CPM.txt TMM normalized counts of reads aligned to mature miRNAs/miRNA precursors (hairpins)
[mature/hairpin]_edgeR_MDS_plot.pdf Multidimensional scaling plot of all samples based on the expression profile of mature miRNAs/miRNA precursors (hairpins)
[mature/hairpin]_CPM_heatmap.pdf Heatmap based on the expression profile of mature miRNAs/miRNA precursors (hairpins)
[mature/hairpin]_log2CPM_sample_distances_dendrogram.pdf Dendrograms of distance among samples based on the expression profile of mature miRNAs/miRNA precursors (hairpins)
[mature/hairpin]_log2CPM_sample_distances_heatmap.pdf Pairwise correlation of samples based on the expression profile of mature miRNAs/miRNA precursors (hairpins)

Example: MDS plot of 10 samples based on their expression profiles of mature miRNAs. Here we can see that samples cluster based on different sample types and library preparation kits.
Example: Heatmap of tumor and normal samples based on the top differentially expressed mature miRNAs.

mirtop
mirtop is used to parse the BAM files from bowtie alignment, and produce a mirgff3 file with information about miRNAs and isomirs.

Output directory: results/mirtop
mirtop.gff: mirgff3 file
mirtop.tsv: tabular file of the previous file for easy integration with downstream analysis.
mirtop_rawData.tsv: File compatible with isomiRs Bioconductor package to perform isomiRs analysis.
mirna.tsv: tabular file with miRNA counts after summarizing unique isomiRs for each miRNA

miRDeep2
miRDeep2 is used for the identification of novel and known miRNAs in deep sequencing data.
Output directory: results/mirdeep2
mirdeep/timestamp_sample.bed File with the known and novel miRNAs in bed format.
mirdeep/timestamp_sample.csv File with an overview of all detected miRNAs (known and novel) in csv format.
mirdeep/timestamp_sample.html A HTML report with an overview of all detected miRNAs (known and novel) in html format.

miRTrace
miRTrace is a quality control specifically for small RNA sequencing data (smRNA-Seq). 
Each sample is characterized by profiling sequencing quality, read length, sequencing depth and miRNA complexity and also the amounts of miRNAs versus undesirable sequences (derived from tRNAs, rRNAs and sequencing artifacts).
Output directory: results/mirtrace
mirtrace-report.html An interactive HTML report summarizing all output statistics from miRTrace
mirtrace-results.json A JSON file with all output statistics from miRTrace
mirtrace-stats-*.tsv Tab-separated statistics files
qc_passed_reads.all.collapsed FASTA file per sample with sequence reads that passed QC in miRTrace
qc_passed_reads.rnatype_unknown.collapsed FASTA file per sample with unknown reads in the RNA type analysis
Refer to the tool manual for detailed specifications about output files. Here is an example of the RNA types plot that you will see:

MultiQC

NB: The FastQC plots displayed in the MultiQC report shows untrimmed reads. They may contain adapter sequence and potentially regions with low quality.
MultiQC
Output files

MultiQC is a visualization tool that generates a single HTML report summarising all samples in your project. Most of the pipeline QC results are visualised in the report and further statistics are available in the report data directory.
Results generated by MultiQC collate pipeline QC from supported tools e.g. FastQC. The pipeline has special steps which also allow the software versions to be reported in the MultiQC output for future traceability. 
For more information about how to use MultiQC reports, see http://multiqc.info.
Pipeline information
Output files
Nextflow provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. 
This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.

Usage documentation:- > https://nf-co.re/smrnaseq/usage 

Introduction
protocol
This option indicates the experimental protocol used for the sample preparation. Currently supporting:
'illumina': adapter (TGGAATTCTCGGGTGCCAAGG)
'nextflex': adapter (TGGAATTCTCGGGTGCCAAGG), clip_r1 (4), three_prime_clip_r1 (4`)
'qiaseq': adapter (AACTGTAGGCACCATCAAT)
'cats': adapter (GATCGGAAGAGCACACGTCTG), clip_r1(3)
'custom' (where the user can indicate the three_prime_adapter, clip_r1 and three_prime_clip_r1 manually)
 At least the custom protocol has to be specified, otherwise the pipeline won't run. In case you specify the custom protocol, ensure that the parameters above are set accordingly or the defaults will be applied. If you want to auto-detect the adapters using fastp, please set --three_prime_adapter to "".
mirtrace_species or mirgenedb_species
It should point to the 3-letter species name used by miRBase or MirGeneDB. Note the difference in case for the two databases.

miRNA related files
Different parameters can be set for the two supported databases. By default miRBase will be used with the parameters below.
mirna_gtf: If not supplied by the user, then mirna_gtf will point to the latest GFF3 file in miRbase: https://mirbase.org/ftp/CURRENT/genomes/${params.mirtrace_species}.gff3
mature: points to the FASTA file of mature miRNA sequences. https://mirbase.org/ftp/CURRENT/mature.fa.gz
hairpin: points to the FASTA file of precursor miRNA sequences. https://mirbase.org/ftp/CURRENT/hairpin.fa.gz
If MirGeneDB should be used instead it needs to be specified using --mirgenedb and use the parameters below .
mirgenedb_gff: The data can not be downloaded automatically (URLs are created with short term tokens in it), thus the user needs to supply the gff file for either his species, or all species downloaded from https://mirgenedb.org/download. The total set will automatically be subsetted to the species specified with --mirgenedb_species.
mirgenedb_mature: points to the FASTA file of mature miRNA sequences. Download from https://mirgenedb.org/download.
mirgenedb_hairpin: points to the FASTA file of precursor miRNA sequences. Download from https://mirgenedb.org/download. Note that MirGeneDB does not have a dedicated hairpin file, but the Precursor sequences are to be used.

Genome
fasta: the reference genome FASTA file
bt_indices: points to the folder containing the bowtie2 indices for the genome reference specified by fasta. Note: if the FASTA file in fasta is not the same file used to generate the bowtie2 indices, then the pipeline will fail.
Contamination filtering
This step has, until now, only been tested for human data. Unexpected behaviour can occur when using it with a different species.
Contamination filtering of the sequencing reads is optional and can be invoked using the filter_contamination parameter. FASTA files with
rrna: Used to supply a FASTA file containing rRNA contamination sequence.
trna: Used to supply a FASTA file containing tRNA contamination sequence. e.g. http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/hg38-tRNAs.fa
cdna: Used to supply a FASTA file containing cDNA contamination sequence. e.g. ftp://ftp.ensembl.org/pub/release-86/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz The FASTA file is first compared to the available miRNA sequences and overlaps are removed.
ncrna: Used to supply a FASTA file containing ncRNA contamination sequence. e.g. ftp://ftp.ensembl.org/pub/release-86/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz The FASTA file is first compared to the available miRNA sequences and overlaps are removed.
pirna: Used to supply a FASTA file containing piRNA contamination sequence. e.g. The FASTA file is first compared to the available miRNA sequences and overlaps are removed.
other_contamination: Used to supply an additional filtering set. The FASTA file is first compared to the available miRNA sequences and overlaps are removed.

Samplesheet input
You will need to create a samplesheet with information about the samples you would like to analyse before running the pipeline. Use this parameter to specify its location. It has to be a comma-separated file with 2 columns ("sample" and "fastq_1"), and a header row as shown in the examples below.
If a second fastq file is provided using another column, the extra data are ignored by this pipeline. The smRNA species should be sufficiently contained in the first read, and so the second read is superfluous data in this smRNA context.
--input '[path to samplesheet file]'

Multiple runs of the same sample
The sample identifiers should match between runs of resequenced samples. The pipeline will concatenate the raw reads before performing any downstream analysis. Below is an example for the same sample sequenced across 3 lanes:
sample,fastq_1
CONTROL_REP1,AEG588A1_S1_L002_R1_001.fastq.gz
CONTROL_REP1,AEG588A1_S1_L003_R1_001.fastq.gz
CONTROL_REP1,AEG588A1_S1_L004_R1_001.fastq.gz
Full samplesheet

The pipeline will auto-detect whether a sample is single- or paired-end using the information provided in the samplesheet. The samplesheet can have as many columns as you desire. 
However, there is a strict requirement for the first 3 columns to match those defined in the table below.
A final samplesheet file consisting of both single- and paired-end data may look something like the one below. This is for 6 samples, where TREATMENT_REP3 has been sequenced twice.
sample,fastq_1
CONTROL_REP1,AEG588A1_S1_L002_R1_001.fastq.gz
CONTROL_REP2,AEG588A2_S2_L002_R1_001.fastq.gz
CONTROL_REP3,AEG588A3_S3_L002_R1_001.fastq.gz
TREATMENT_REP1,AEG588A4_S4_L003_R1_001.fastq.gz
TREATMENT_REP2,AEG588A5_S5_L003_R1_001.fastq.gz
TREATMENT_REP3,AEG588A6_S6_L003_R1_001.fastq.gz
TREATMENT_REP3,AEG588A6_S6_L004_R1_001.fastq.gz

Column
Description
sample
Custom sample name. This entry will be identical for multiple sequencing libraries/runs from the same sample. Spaces in sample names are automatically converted to underscores (_).
fastq_1
Full path to FastQ file for Illumina short reads 1. File has to be gzipped and have the extension ".fastq.gz" or ".fq.gz".

An example samplesheet has been provided with the pipeline.
Running the pipeline
The typical command for running the pipeline is as follows:
nextflow run nf-core/smrnaseq --input samplesheet.csv --outdir <OUTDIR> --genome GRCh37 -profile docker
This will launch the pipeline with the docker configuration profile. See below for more information about profiles.
Note that the pipeline will create the following files in your working directory:
work                # Directory containing the nextflow working files
<OUTDIR>            # Finished results in specified location (defined with --outdir)
.nextflow_log       # Log file from Nextflow
# Other nextflow hidden files, eg. history of pipeline runs and old logs.
If you wish to repeatedly use the same parameters for multiple runs, rather than specifying each flag in the command, you can specify these in a params file.
Pipeline settings can be provided in a yaml or json file via -params-file <file>.
⚠️ Do not use -c <file> to specify parameters as this will result in errors. Custom config files specified with -c must only be used for tuning process resource specifications, other infrastructural tweaks (such as output directories), or module arguments (args). The above pipeline run specified with a params file in yaml format:
nextflow run nf-core/smrnaseq -profile docker -params-file params.yaml
with params.yaml containing:
input: './samplesheet.csv'
outdir: './results/'
genome: 'GRCh37'
input: 'data'
<...>
You can also generate such YAML/JSON files via nf-core/launch.

Updating the pipeline
When you run the above command, Nextflow automatically pulls the pipeline code from GitHub and stores it as a cached version. When running the pipeline after this, it will always use the cached version if available - even if the pipeline has been updated since. To make sure that you're running the latest version of the pipeline, make sure that you regularly update the cached version of the pipeline:
nextflow pull nf-core/smrnaseq

Reproducibility
It is a good idea to specify a pipeline version when running the pipeline on your data. This ensures that a specific version of the pipeline code and software are used when you run your pipeline. If you keep using the same tag, you'll be running the same version of the pipeline, even if there have been changes to the code since.
First, go to the nf-core/smrnaseq releases page and find the latest pipeline version - numeric only (eg. 1.3.1). Then specify this when running the pipeline with -r (one hyphen) - eg. -r 1.3.1. Of course, you can switch to another version by changing the number after the -r flag.
This version number will be logged in reports when you run the pipeline, so that you'll know what you used when you look back in the future.
Stand-alone scripts
The bin directory contains some scripts used by the pipeline which may also be run manually:
edgeR_miRBase.r: R script using for processing reads counts of mature miRNAs and miRNA precursors (hairpins). This version number will be logged in reports when you run the pipeline, so that you'll know what you used when you look back in the future. For example, at the bottom of the MultiQC reports.
To further assist in reproducbility, you can use share and re-use parameter files to repeat pipeline runs with the same settings without having to write out a command with every single parameter.
💡 If you wish to share such profile (such as upload as supplementary material for academic publications), make sure to NOT include cluster specific paths to files, nor institutional specific profiles.
Core Nextflow arguments
NB: These options are part of Nextflow and use a single hyphen (pipeline parameters use a double-hyphen).
-profile

Use this parameter to choose a configuration profile. Profiles can give configuration presets for different compute environments.
Several generic profiles are bundled with the pipeline which instruct the pipeline to use software packaged using different methods (Docker, Singularity, Podman, Shifter, Charliecloud, Apptainer, Conda) - see below.
We highly recommend the use of Docker or Singularity containers for full pipeline reproducibility, however when this is not possible, Conda is also supported.
The pipeline also dynamically loads configurations from https://github.com/nf-core/configs when it runs, making multiple config profiles for various institutional clusters available at run time. For more information and to see if your system is available in these configs please see the nf-core/configs documentation.
Note that multiple profiles can be loaded, for example: -profile test,docker - the order of arguments is important! They are loaded in sequence, so later profiles can overwrite earlier profiles.
If -profile is not specified, the pipeline will run locally and expect all software to be installed and available on the PATH. This is not recommended, since it can lead to different results on different machines dependent on the computer enviroment.
test
A profile with a complete configuration for automated testing
Includes links to test data so needs no other parameters
docker: A generic configuration profile to be used with Docker
singularity: A generic configuration profile to be used with Singularity
podman: A generic configuration profile to be used with Podman
shifter: A generic configuration profile to be used with Shifter
charliecloud: A generic configuration profile to be used with Charliecloud
apptainer: A generic configuration profile to be used with Apptainer
conda: A generic configuration profile to be used with Conda. Please only use Conda as a last resort i.e. when it's not possible to run the pipeline with Docker, Singularity, Podman, Shifter, Charliecloud, or Apptainer.
-resume
Specify this when restarting a pipeline. Nextflow will use cached results from any pipeline steps where the inputs are the same, continuing from where it got to previously. For input to be considered the same, not only the names must be identical but the files' contents as well. For more info about this parameter, see this blog post.
You can also supply a run name to resume a specific run: -resume [run-name]. Use the nextflow log command to show previous run names.
-c
Specify the path to a specific config file (this is a core Nextflow command). See the nf-core website documentation for more information.


